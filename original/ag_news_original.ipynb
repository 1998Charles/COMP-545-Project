{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4098,
     "status": "ok",
     "timestamp": 1712297717629,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "kTlWH2I19r0z"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2624,
     "status": "ok",
     "timestamp": 1712297720224,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "6vP_FCv494vP",
    "outputId": "347661db-819e-430f-d004-1466802a4245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ag_news = load_dataset(\"ag_news\")\n",
    "print(ag_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1712297720759,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "bOpDCfZF-dub",
    "outputId": "4fcb5bf6-8b33-41ed-b43d-ad7681fec2f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(ag_news['train']['text']))\n",
    "print(type(ag_news['train']['text'][0]))\n",
    "print(ag_news['train']['text'][0])\n",
    "print(type(ag_news['train']['label']))\n",
    "print(type(ag_news['train']['label'][0]))\n",
    "print(ag_news['train']['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(ag_news['test']['text']))\n",
    "print(type(ag_news['test']['text'][0]))\n",
    "print(ag_news['test']['text'][0])\n",
    "print(type(ag_news['test']['label']))\n",
    "print(type(ag_news['test']['label'][0]))\n",
    "print(ag_news['test']['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712297720760,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "QHp6fC4gBwHH"
   },
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712297720760,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "8XMt4NxH-69i"
   },
   "outputs": [],
   "source": [
    "dataset = ag_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 24248,
     "status": "ok",
     "timestamp": 1712297745002,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "XC3LV2fF-7Ye"
   },
   "outputs": [],
   "source": [
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "\n",
    "with open(\"train.txt\", \"w\") as f:\n",
    "    for text, label in zip(train_texts, train_labels):\n",
    "        f.write(f\"__label__{label} {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "with open(\"test.txt\", \"w\") as f:\n",
    "    for text, label in zip(test_texts, test_labels):\n",
    "        f.write(f\"__label__{label} {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with lr=0.05, dim=10, epoch=5, and wordNgrams=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 8123139 lr:  0.000000 avg.loss:  0.312559 ETA:   0h 0m 0s\n",
      "Read 1M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.913\n",
      "R@1\t0.913\n",
      "\n",
      "Training model with lr=0.1, dim=10, epoch=5, and wordNgrams=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 8270125 lr:  0.000000 avg.loss:  0.243690 ETA:   0h 0m 0s\n",
      "Read 1M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.914\n",
      "R@1\t0.914\n",
      "\n",
      "Training model with lr=0.25, dim=10, epoch=5, and wordNgrams=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 8216088 lr:  0.000000 avg.loss:  0.214442 ETA:   0h 0m 0s\n",
      "Read 1M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.914\n",
      "R@1\t0.914\n",
      "\n",
      "Training model with lr=0.5, dim=10, epoch=5, and wordNgrams=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress:  52.5% words/sec/thread: 8726498 lr:  0.237640 avg.loss:  0.292023 ETA:   0h 0m 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.913\n",
      "R@1\t0.913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread: 8250533 lr:  0.000000 avg.loss:  0.208962 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.1, 0.25, 0.5]\n",
    "dim_list = [10] # hidden units\n",
    "ngrams_list = [1]\n",
    "epoch_list = [5]\n",
    "\n",
    "best_p, best_r = 0, 0\n",
    "best_l, best_d, best_n, best_e = 0, 0, 0, 0\n",
    "\n",
    "for l in lr_list:\n",
    "    for d in dim_list:\n",
    "        for n in ngrams_list:\n",
    "            for e in epoch_list:\n",
    "                print(f\"Training model with lr={l}, dim={d}, epoch={e}, and wordNgrams={n}\")\n",
    "                model = fasttext.train_supervised(input='train.txt', lr=l, dim=d, epoch=e, wordNgrams=n)\n",
    "                N, p, r = model.test('test.txt')\n",
    "                print_results(N, p, r)\n",
    "                if p > best_p and r > best_r:\n",
    "                    best_p, best_r = p, r\n",
    "                    best_l, best_d, best_n, best_e = l, d, n, e\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1712297745153,
     "user": {
      "displayName": "Mengtong Shi",
      "userId": "17422019785472594156"
     },
     "user_tz": 240
    },
    "id": "MKSt6qX1-70H",
    "outputId": "2bdf2ee4-8440-4d45-9b9c-f13da2297232"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the best model with lr=0.1, dim=10, epoch=5, and wordNgrams=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 8191716 lr:  0.000000 avg.loss:  0.229802 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training the best model with lr={best_l}, dim={best_d}, epoch={best_e}, and wordNgrams={best_n}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = fasttext.train_supervised(input='train.txt', lr=best_l, dim=best_d, epoch=best_e, wordNgrams=best_n, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.6706719398498535 seconds\n",
      "Accuracy: 0.9167105263157894\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "\n",
    "predictions = []\n",
    "for text in test_texts:\n",
    "    prediction = model.predict(text)\n",
    "    predictions.append(int(prediction[0][0].split('__label__')[1]))\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with lr=0.05, dim=10, epoch=5, and wordNgrams=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 4733911 lr:  0.000000 avg.loss:  0.355953 ETA:   0h 0m 0s\n",
      "Read 3M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.911\n",
      "R@1\t0.911\n",
      "\n",
      "Training model with lr=0.1, dim=10, epoch=5, and wordNgrams=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 5474497 lr:  0.000000 avg.loss:  0.225286 ETA:   0h 0m 0s\n",
      "Read 4M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.917\n",
      "R@1\t0.917\n",
      "\n",
      "Training model with lr=0.25, dim=10, epoch=5, and wordNgrams=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 4732799 lr:  0.000000 avg.loss:  0.143234 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.919\n",
      "R@1\t0.919\n",
      "\n",
      "Training model with lr=0.5, dim=10, epoch=5, and wordNgrams=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress:  85.2% words/sec/thread: 5687812 lr:  0.074111 avg.loss:  0.148198 ETA:   0h 0m 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t7600\n",
      "P@1\t0.917\n",
      "R@1\t0.917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread: 5538546 lr:  0.000000 avg.loss:  0.123914 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.1, 0.25, 0.5]\n",
    "dim_list = [10] # hidden units\n",
    "ngrams_list = [2]\n",
    "epoch_list = [5]\n",
    "\n",
    "best_p, best_r = 0, 0\n",
    "best_l, best_d, best_n, best_e = 0, 0, 0, 0\n",
    "\n",
    "for l in lr_list:\n",
    "    for d in dim_list:\n",
    "        for n in ngrams_list:\n",
    "            for e in epoch_list:\n",
    "                print(f\"Training model with lr={l}, dim={d}, epoch={e}, and wordNgrams={n}\")\n",
    "                model = fasttext.train_supervised(input='train.txt', lr=l, dim=d, epoch=e, wordNgrams=n)\n",
    "                N, p, r = model.test('test.txt')\n",
    "                print_results(N, p, r)\n",
    "                if p > best_p and r > best_r:\n",
    "                    best_p, best_r = p, r\n",
    "                    best_l, best_d, best_n, best_e = l, d, n, e\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 3M words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the best model with lr=0.25, dim=10, epoch=5, and wordNgrams=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  188111\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 5465766 lr:  0.000000 avg.loss:  0.145287 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training the best model with lr={best_l}, dim={best_d}, epoch={best_e}, and wordNgrams={best_n}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = fasttext.train_supervised(input='train.txt', lr=best_l, dim=best_d, epoch=best_e, wordNgrams=best_n, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.908433198928833 seconds\n",
      "Accuracy: 0.9186842105263158\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "\n",
    "predictions = []\n",
    "for text in test_texts:\n",
    "    prediction = model.predict(text)\n",
    "    predictions.append(int(prediction[0][0].split('__label__')[1]))\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMVG60DvXC81i+vxe2BsbyR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
